

# 2022-è‡ªåŠ¨åŒ–æµ‹è¯•-è­¦å‘Šè¯†åˆ«

[TOC]

## 1.ç®€ä»‹

æœ¬é¡¹ç›®ä¸»è¦æ˜¯åŸºäºç½®ä¿¡å­¦ä¹ æŠ€æœ¯ï¼Œå¯¹apacheé¡¹ç›®ä¸­çš„è­¦å‘Šæ•°æ®é›†è¿›è¡Œå»å™ªã€‚

æœ¬é¡¹ç›®çš„å·¥ä½œä¸»è¦åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€ä¸ªé˜¶æ®µï¼Œåˆ©ç”¨githubä¸Šç°æœ‰çš„é¡¹ç›®

findbugs-violation (https://github.com/lxyeah/findbugs-violations) ï¼Œæ”¶é›†githubä¸Šçš„apacheé¡¹ç›®çš„è­¦å‘Šæ•°æ®é›†ã€‚ç¬¬äºŒä¸ªé˜¶æ®µï¼Œåˆ©ç”¨cleanlabè¿™ä¸€pythonåŒ…ï¼Œå¯¹æ•°æ®é›†è¿›è¡Œå»å™ªï¼Œå¹¶å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚

ä¸‹é¢æˆ‘ä»¬å°†å¯¹äºä»¥ä¸‹ä¸¤ä¸ªéƒ¨åˆ†åˆ†åˆ«å±•å¼€ä»‹ç»æˆ‘ä»¬çš„å·¥ä½œè¿‡ç¨‹å’Œå¿ƒè·¯å†ç¨‹ï¼Œæœ€åä¼šé™„ä¸Šæœ¬é¡¹ç›®çš„è¯´æ˜ä¹¦ã€‚

## 2.æ•°æ®é›†æ”¶é›†ä¸æ ‡è®°

### 2.1æ”¶é›†æ•°æ®é›†

//todo

### 2.2æ•°æ®é›†æ ‡è®°

å¦‚ä¸Šä¸€éƒ¨åˆ†æ‰€æåˆ°çš„ï¼Œå¯¹äºè¯¥apacheé¡¹ç›®biojavaæˆ‘ä»¬ä¸€å…±æ”¶é›†åˆ°äº†1967ä»½æœ‰æ•ˆè­¦å‘Šå’Œ10ä¸‡ä½™ä»½æ— æ•ˆè­¦å‘Šã€‚å…¶ä¸­ï¼Œæˆ‘ä»¬å¯¹äºæ‰€æœ‰çš„æœ‰æ•ˆè­¦å‘Šè¿›è¡Œäº†äººå·¥æ ‡è®°ï¼Œå¯¹äºæ‰€æœ‰çš„æ— æ•ˆè­¦å‘Šæˆ‘ä»¬æŒ‰50ï¼š1çš„æ¯”ä¾‹è¿›è¡Œäº†åˆ†å±‚æŠ½æ ·ç„¶åæ ‡è®°ã€‚ä¹Ÿå°±æ˜¯æ€»çš„æ ‡è®°æ•°é‡åœ¨4000ä»½å·¦å³ã€‚

æˆ‘ä»¬é¦–å…ˆäº†è§£äº†å¯¹äºæ¯ä¸€ç§è­¦å‘Šç±»å‹æ‰€ä»£è¡¨çš„å«ä¹‰ï¼Œæ ¹æ®findbugsåœ¨githubä¸Šçš„æ–‡æ¡£ [colin2wang/findbugs-description](https://github.com/colin2wang/findbugs-description) ã€‚è¿™æ ·ä¾¿äºæˆ‘ä»¬è¯†åˆ«è¯¥è­¦å‘Šæ˜¯å¦å±äºfindbugsæ‰€æ ‡è®°çš„è­¦å‘Šç±»å‹ã€‚

äº†è§£äº†è­¦å‘Šç±»å‹çš„å«ä¹‰ä¹‹åæˆ‘ä»¬æ­£å¼å¯åŠ¨äº†æˆ‘ä»¬çš„æ ‡è®°ä¹‹è·¯ã€‚å¯¹äºæ¯ä¸€æ¡è­¦å‘Šè€Œè¨€ï¼Œæˆ‘ä»¬éƒ½éœ€è¦å¤§çº¦ä¸€åˆ†é’Ÿçš„æ—¶é—´å»æ›´æ¢åˆ°å¯¹åº”çš„ç‰ˆæœ¬ï¼Œæ‰¾åˆ°è­¦å‘Šæ‰€åœ¨ä½ç½®ï¼Œå¹¶æ ¹æ®ä¸Šä¸‹æ–‡å’Œè‡ªèº«çš„javaåŸºç¡€çŸ¥è¯†æ¥åˆ¤æ–­è¯¥è­¦å‘Šæ˜¯å¦ä¸ºæœ‰æ•ˆè­¦å‘Šã€‚ä½†æ˜¯å—é™äºæˆ‘ä»¬å¯¹äºjavaçš„æ·±åº¦ï¼Œæˆ‘ä»¬ä¸èƒ½ä¿è¯æ¯ä¸€ä¸ªè¢«æ ‡è®°çš„è­¦å‘Šéƒ½æ˜¯æ­£ç¡®çš„ï¼Œä½†æ˜¯èƒ½ä¿è¯æˆ‘ä»¬æ ‡è®°çš„æ¯ä¸€æ¡è­¦å‘Šéƒ½æ˜¯æˆ‘ä»¬ç»è¿‡è‡ªèº«æ€è€ƒä¹‹åç»™å‡ºçš„è‡ªå·±è®¤ä¸ºæœ€ç¨³å¦¥çš„ç­”æ¡ˆã€‚

åœ¨æ ‡è®°ä¸­æˆ‘ä»¬å‘ç°ï¼Œå¯¹äºä¸€äº›ç‰¹å®šçš„è­¦å‘Šç±»å‹æ ‡è®°çš„æ­£ç¡®æ€§æ¯”è¾ƒé«˜ï¼Œæˆ‘ä»¬æ¨æµ‹æ˜¯å› ä¸ºè¿™ä¸€ç±»çš„è­¦å‘Šæ¯”è¾ƒå®¹æ˜“æ£€æµ‹ã€‚ä¾‹å¦‚MS_SHOULD_BE_FINALï¼Œåªéœ€è¦æ‰«æä¸€ä¸ªå˜é‡è¢«å£°æ˜åæœ‰æ— æ”¹åŠ¨å³å¯ã€‚è¿™å¯¹äºæˆ‘ä»¬åç»­çš„ç½®ä¿¡å­¦ä¹ éƒ¨åˆ†æä¾›äº†ä¸€äº›å¯å‘ï¼Œä¹Ÿè®¸å¯ä»¥åˆ©ç”¨è­¦å‘Šç±»å‹è¿™ä¸€ç»´åº¦çš„æ•°æ®ç‰¹å¾å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚

å¦å¤–ï¼Œåœ¨æ ‡è®°çš„è¿‡ç¨‹ä¸­é˜…è¯»æºç æ—¶æˆ‘ä»¬å‘ç°ï¼Œå¯¹äºå¾ˆå¤šè­¦å‘Šè€Œè¨€ï¼Œæºç ä¸­åœ¨è·Ÿè¸ªä¸ç›¸é‚»commitæ—¶ä¼šå‡ºç°é—®é¢˜ï¼Œå¯¼è‡´è­¦å‘Šç”Ÿå‘½å‘¨æœŸé“¾æ–­è£‚ï¼Œé€ æˆè¯¯æŠ¥ ã€‚å…·ä½“æ¥è¯´å°±æ˜¯ï¼Œå¯¹äºåŒä¸€ä¸ªä½ç½®æºç çš„è­¦å‘Šï¼Œå¯èƒ½åœ¨æŸä¸€ä¸ªç‰ˆæœ¬è¢«ä¿®å¤äº†ï¼Œä½†æ˜¯ä¼šåœ¨å¦å¤–ä¸€ä¸ªç‰ˆæœ¬åœ¨æ¬¡è¢«æŠ›å‡ºï¼Œè¿™å°±ç»™æˆ‘ä»¬çš„æ ‡è®°å·¥ä½œå¢æ·»ä¸å¿…è¦çš„å·¥ä½œé‡ã€‚

## 3.åŸºäºç½®ä¿¡å­¦ä¹ å»å™ª

### 3.1ç½®ä¿¡å­¦ä¹ åˆæ¢

é¦–å…ˆï¼Œæˆ‘ä»¬åˆæ­¥äº†è§£äº†ç½®ä¿¡å­¦ä¹ é¢†åŸŸï¼Œå‘ç°è¿™æ˜¯ä¸€ä¸ªè¾ƒä¸ºå‰æ²¿çš„é¢†åŸŸï¼Œå¯ä»¥å€Ÿé‰´çš„å†…å®¹å¹¶ä¸å¤šã€‚äºæ˜¯æˆ‘ä»¬è‡ªå·±ç ”è¯»äº†æœ‰å…³ç½®ä¿¡å­¦ä¹ çš„è®ºæ–‡ï¼šConfident Learning: Estimating Uncertainty in Dataset Labelsã€‚å¯¹äºç½®ä¿¡å­¦ä¹ æœ‰äº†ä¸€ä¸ªåˆæ­¥çš„äº†è§£ï¼šå¤§è‡´å°±æ˜¯å…ˆè®¡ç®—å‡ºæ•°æ®æ ‡ç­¾çš„æ¦‚ç‡åˆ†å¸ƒï¼Œç„¶åè·Ÿäººå·¥æ ‡è®°çš„æ ‡ç­¾è¿›è¡Œæ¯”å¯¹ï¼ˆæ­¤å¤„åˆ™æ˜¯findbugsè‡ªåŠ¨æ ‡æ³¨çš„æ ‡ç­¾ï¼‰ï¼Œæœ€åæ‰¾å‡ºæœ€æœ‰å¯èƒ½æ˜¯å™ªå£°çš„æ ·æœ¬ã€‚å¯¹äºå¤§ä½“çš„æ¡†æ¶å…¶å®ä¸éš¾ç†è§£ï¼Œä½†æ˜¯è½å®åˆ°å…·ä½“çš„ç®—æ³•ä¹‹ä¸Šå°±æœ‰äº›è®¸é»”é©´æŠ€ç©·çš„æ„Ÿè§‰äº†ã€‚

### 3.2æ•°æ®é›†é¢„å¤„ç†

å¯¹äºç¬¬ä¸€é˜¶æ®µæ”¶é›†åˆ°çš„æ•°æ®é›†è€Œè¨€ï¼Œå¤§è‡´å½¢å¦‚ä¸‹è¡¨

æœ‰æ•ˆè­¦å‘Šï¼š

| è­¦å‘Šç±»å‹     | æŠ¥è­¦å‘Šç‰ˆæœ¬çš„commit id | è­¦å‘Šåœ¨é¡¹ç›®ä¸­çš„ä½ç½®     | è­¦å‘Šæ¶ˆå¤±ç‰ˆæœ¬çš„commit id | è­¦å‘Šæ¶ˆå¤±ç‰ˆæœ¬æ—¶åœ¨é¡¹ç›®ä¸­çš„ä½ç½® | æœ‰æ•ˆ |
| ------------ | --------------------- | ---------------------- | ----------------------- | ---------------------------- | ---- |
| æœªä½¿ç”¨çš„æ•°æ® | ....                  | ..../main/..../xx.java | ......                  | ..../main/..../xx.java       | æ˜¯   |

æ— æ•ˆè­¦å‘Šï¼š

| è­¦å‘Šç±»å‹     | æŠ¥è­¦å‘Šç‰ˆæœ¬çš„commit id | åœ¨é¡¹ç›®ä¸­çš„ä½ç½®         | æœ‰æ•ˆ |
| ------------ | --------------------- | ---------------------- | ---- |
| æœªä½¿ç”¨çš„æ•°æ® | ....                  | ..../main/..../xx.java | å¦   |



å¾—åˆ°æ•°æ®é›†ä¹‹åè¦è€ƒè™‘çš„å°±æ˜¯é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„è®­ç»ƒæ¨¡å‹æ¥è¾“å…¥æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚

#### 3.2.1è®­ç»ƒæ¨¡å‹çš„é€‰æ‹©ï¼š

æˆ‘ä»¬ä¹Ÿæœ‰è€ƒè™‘è¿‡åŸºäºè¡¨æ ¼æ•°æ®å’ŒåŸºäºæ–‡æœ¬çš„å½¢å¼æ¥è®­ç»ƒæ¨¡å‹ï¼Œä½†æ˜¯å—é™äºâ€œè­¦å‘Šåœ¨é¡¹ç›®ä¸­çš„ä½ç½®â€ä¹‹ç±»çš„æ•°æ®èŒƒå›´å¤ªå¤§ï¼ˆå³å¯èƒ½å‡ºç°å„ç§å„æ ·çš„è·¯å¾„ï¼‰ï¼Œè€Œä¸”å­—ç¬¦ä¸²é•¿åº¦è¿‡é•¿ï¼Œä¸åˆ©äºå½“ä½œè¡¨æ ¼æ•°æ®è¿›è¡Œè®­ç»ƒã€‚è€Œå¯¹äºåŸºäºæ–‡æœ¬è®­ç»ƒçš„æ¨¡å‹æ¥è¯´ï¼Œæ•°æ®èŒƒå›´ç•¥å¤§å¹¶ä¸ä¼šå¯¹äºæ¨¡å‹è®­ç»ƒäº§ç”Ÿå½±å“ã€‚æ¯”å¦‚å¯¹äºè¡¨æ ¼æ•°æ®æ¥è¯´ï¼Œè¡¨é¡¹ä¸­çš„æ•°æ®æ— éå°±æ˜¯æ•°å­—ï¼ˆintï¼Œfloatï¼Œdoubleç­‰ï¼‰ï¼Œæˆ–è€…æ˜¯ä¸€äº›ç±»å‹ï¼ˆcategoryï¼‰ï¼ˆegï¼šcashï¼Œcredit cardï¼Œwechat-payï¼Œali-payç­‰ï¼‰ï¼Œæ•°æ®èŒƒå›´ç•¥å°ã€‚è€Œæ–‡æœ¬æ•°æ®æ¥è¯´ï¼Œæ•°æ®é¡¹ç±»ä¼¼äºä¸€æ®µè¯è¿™æ ·çš„é•¿å­—ç¬¦ä¸²ï¼Œè€Œä¸”æ²¡æœ‰ä»»ä½•é™åˆ¶ï¼Œè¿™æ ·çš„æ•°æ®èŒƒå›´è¾ƒä¸ºé€‚åˆè®­ç»ƒè­¦å‘Šæ•°æ®é›†ã€‚

ç›¸æ¯”è¾ƒè€Œè¨€ï¼ŒäºŒè€…çš„å…±åŒç‚¹æ˜¯ï¼šå®ƒä»¬éƒ½å°†æ•°æ®è¿›è¡Œæ‹†åˆ†ç„¶åè½¬åŒ–æˆå‘é‡æ”¾å…¥æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚ä¸åŒç‚¹æ˜¯ï¼šæ„Ÿè§‰ä¸Šè¡¨æ ¼æ•°æ®çš„å–å€¼æ˜¯â€œç¦»æ•£â€çš„ï¼Œè€Œæ–‡æœ¬æ•°æ®çš„å–å€¼æ˜¯â€œè¿ç»­â€çš„ã€‚

#### 3.2.2æ•°æ®ç‰¹å¾çš„å¢åŠ å’Œä¼˜åŒ–

å¯¹äºç¬¬ä¸€é˜¶æ®µäº§ç”Ÿçš„æ•°æ®è€Œè¨€ï¼Œè¦æƒ³ç›´æ¥è®­ç»ƒå‡ºä¸€ä¸ªæ‹Ÿåˆæ•ˆæœä¸é”™çš„æ¨¡å‹æ— ç–‘æ˜¯å›°éš¾çš„ï¼Œæ‰€ä»¥è¯´åœ¨è¿™é‡Œæˆ‘ä»¬å°ç»„ä¹Ÿè·Ÿå…¶ä»–å°ç»„å°±æ•°æ®é›†å¤„ç†è¿™ä¸ªä¸€é—®é¢˜è¿›è¡Œäº†ä¸€äº›è®¨è®ºã€‚

å¯¹äºè¿™æ ·çš„æ•°æ®é›†æ¥è¯´ï¼Œä¸»è¦æœ‰ä¸¤ä¸ªé—®é¢˜ï¼šç¬¬ä¸€ï¼šç‰¹å¾ç»´åº¦æ¥è¯´è¿‡äºä½ã€‚ç¬¬äºŒï¼šæœ‰æ•ˆçš„è®­ç»ƒç‰¹å¾æ›´æ˜¯ä¸è¶³ã€‚ä¸‹é¢å°†åˆ†åˆ«å±•å¼€å¯¹äºè¿™ä¸¤ä¸ªé—®é¢˜æˆ‘ä»¬æä¾›çš„æ”¹è¿›æ–¹æ³•ã€‚

> /*
>
> åœ¨é˜è¿°ç¬¬ä¸€ç¬¬äºŒç‚¹ä¹‹å‰ï¼Œå…ˆé˜è¿°ä¸€ä¸‹åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çŠ¯ä¸‹çš„ä¸€ä¸ªä¸¥é‡è€Œåˆä½çº§çš„é”™è¯¯
>
> ç¬¬é›¶ç‚¹ï¼šç»Ÿä¸€æ•°æ®æ ¼å¼
>
> å› ä¸ºæ­£å‘Šæ•°æ®é›†ï¼Œè·Ÿè¯¯å‘Šæ•°æ®é›†æ ¼å¼ä¸åŒï¼Œæ‰€ä»¥å¦‚æœç›´æ¥æŠŠäºŒè€…æ‰“ä¹±è¿›è¡Œè®­ç»ƒçš„è¯æ¨¡å‹å¾ˆå¯èƒ½å°±ä»…ä»…æ ¹æ®æ ¼å¼ä¸Šçš„ä¸åŒè€Œäº§ç”Ÿè¾“å‡ºï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆåœ¨æ²¡æœ‰ç»Ÿä¸€æ ¼å¼ä¹‹å‰çš„æ‹Ÿåˆç»“æœæ¥è¿‘äº100%çš„åŸå› ã€‚è¿™ä¹Ÿæ˜¯å¯¹äºæœºå™¨å­¦ä¹ é¢†åŸŸçš„ä¸ç†Ÿæ‚‰è€ŒçŠ¯ä¸‹çš„å¯ç¬‘çš„é”™è¯¯ï¼Œçœ‹æ¥ä»¥åè¿˜è¦å¡«è¡¥ä¸€ä¸‹æœºå™¨å­¦ä¹ é¢†åŸŸçš„çŸ¥è¯†ã€‚ğŸ˜¥
>
> */

**ç¬¬ä¸€ï¼šå¢åŠ ç‰¹å¾çš„ç»´åº¦**

åœ¨è­¦å‘Šæ•°æ®é›†ä¸­çš„æ¯ä¸€ä¸ªè­¦å‘Šéƒ½æ˜¯æ¥è‡ªäºfindbugså·¥å…·è‡ªå¸¦çš„è­¦å‘Šç±»å‹ã€‚å¹¸è¿çš„æ˜¯ï¼Œfindbugsçš„æ–‡æ¡£ä¸­å¯¹äºæ¯ä¸ªè­¦å‘Šç±»å‹éƒ½å½’ç»“ä¸ºäº†ä¸€ä¸ªå¤§ç±»å‹ï¼ˆä¹Ÿå¯ä»¥ç§°ä¹‹ä¸ºè­¦å‘Šçº§åˆ«ï¼ˆrankï¼‰ï¼‰ï¼Œåˆ†åˆ«æ˜¯  Bad practice ï¼Œ Correctness ï¼Œ Experimental ï¼Œ Internationalization ï¼Œ Malicious code vulnerability ï¼Œ Malicious code vulnerability ï¼Œ Performance ï¼Œ Security ï¼Œ Dodgy code ã€‚å…¶ä¸­æ¯ä¸ªç±»å‹ä¹Ÿæœ‰å¯¹åº”çš„ä¸¥é‡ç¨‹åº¦ï¼Œä¾‹å¦‚ Bad practiceå°±æ˜¯ä¸€äº›ç¼–ç çš„åä¹ æƒ¯ï¼Œå¯¹äºç¨‹åºçš„æ­£ç¡®æ­£å¸¸è¿è¡Œæ²¡æœ‰å¤ªå¤§å½±å“ï¼ŒCorrectness å°±æ˜¯ä¼šå½±å“ç¨‹åºçš„æ­£ç¡®è¿è¡Œçš„ç±»å‹ã€‚æ‰€ä»¥è¯´æˆ‘ä»¬æ ¹æ®æ¯ä¸ªè­¦å‘Šç±»å‹å¯¹åº”çš„è­¦å‘Šçº§åˆ«ï¼Œä½œä¸ºä¸€ä¸ªå…¨æ–°çš„ç»´åº¦ä¹ŸåŠ å…¥åˆ°äº†æ•°æ®é›†å½“ä¸­ã€‚è¿™å°†ä¼šæ›´æœ‰åˆ©äºæ¨¡å‹å­¦ä¹ åˆ°è­¦å‘Šç±»å‹çš„ç‰¹å¾ã€‚



**ç¬¬äºŒï¼šå¢åŠ ç‰¹å¾çš„æœ‰æ•ˆæ€§**

å¯¹äºcommit idæ¥è¯´ï¼Œæœ¬è´¨ä¸Šå°±æ˜¯éšæœºäº§ç”Ÿçš„ä¸€ä¸²å­—ç¬¦ï¼Œæ²¡æœ‰ä»»ä½•å¯ä»¥æå–å‡ºæ¥çš„ç‰¹å¾ã€‚ä¸éš¾é¢„æ–™å¯¹äºè¿™æ ·çš„æ•°æ®ç±»å‹æ”¾å…¥æ¨¡å‹è®­ç»ƒä¹‹åå­¦ä¹ çš„æ•ˆæœåªä¼šå°‘ä¹‹åˆå°‘ã€‚é€šè¿‡å°ç»„é—´çš„è®¨è®ºä¹‹åæˆ‘ä»¬ä¸€è‡´è®¤ä¸ºï¼Œcommit idéœ€è¦è½¬æ¢ä¸ºä¸€ä¸ªå¯èƒ½ä¼šæœ‰äº§å‡ºçš„æ•°æ®â€”â€”commit çš„æ—¥æœŸï¼Œå¦‚æœæœ‰äº†ä¸€ä¸ªcommitå…ˆåé¡ºåºçš„ä¿¡æ¯åŠ å…¥å…¶ä¸­ï¼Œå¯èƒ½ä¼šå¯¹æ¨¡å‹çš„è®­ç»ƒæœ‰æ‰€å¸®åŠ©ã€‚ä¾‹å¦‚ï¼Œ2015å¹´ä¹‹å‰çš„è­¦å‘Šå¤§å¤šéƒ½æ˜¯æ— æ•ˆè­¦å‘Šã€‚æ‰€ä»¥æˆ‘ä»¬åˆ©ç”¨pythonè‡ªå¸¦çš„gitåŒ…æ¥æŠŠæ•°æ®ä¸­æ‰€æœ‰çš„commit idæ›´æ¢æˆäº†commitçš„æ—¥æœŸã€‚



ç»¼åˆä»¥ä¸Šä¸¤ç‚¹ï¼Œå°†åˆå§‹çš„æ•°æ®é›†å¤„ç†ä¹‹åçš„æ•°æ®é›†å½¢å¦‚ä¸‹è¡¨

| è­¦å‘Šç±»å‹rank | è­¦å‘Šç±»å‹     | æäº¤æ—¶é—´       | è­¦å‘Šä½ç½®             | æœ‰æ•ˆ  |
| ------------ | ------------ | -------------- | -------------------- | ----- |
| correctness  | æœªä½¿ç”¨çš„æ•°æ® | 20151012140506 | ../../src/../xx.java | æ˜¯/å¦ |

å¯ä»¥çœ‹åˆ°ï¼Œä¿®æ”¹ä¹‹åçš„æ•°æ®é›†çš„ç‰¹å¾ç»´åº¦æœ‰æ‰€å¢åŠ ï¼Œè€Œä¸”ç‰¹å¾çš„æœ‰æ•ˆæ€§å¾—åˆ°äº†æé«˜ã€‚è™½ç„¶æœ¬æ¬¡å®éªŒè¿‡ç¨‹ä¸­æ²¡æœ‰ç”¨åŸå§‹çš„æ•°æ®é›†è¿›è¡Œå¯¹ç…§å®éªŒï¼Œä½†æ˜¯ä¸éš¾é¢„æƒ³å¤„ç†åçš„æ•°æ®é›†å¯¹äºæ¨¡å‹çš„è®­ç»ƒæ•ˆæœä¼šæœ‰æ˜æ˜¾çš„æå‡ã€‚

### 3.3ç½®ä¿¡å­¦ä¹ å»å™ª

æœ¬æ¬¡å®éªŒä½¿ç”¨äº†åŸºäºpythonçš„ç½®ä¿¡å­¦ä¹ å·¥å…·cleanlabæ¥å¯¹å™ªå£°æ•°æ®è¿›è¡Œç½®ä¿¡å­¦ä¹ ã€‚ç½®ä¿¡å­¦ä¹ çš„å¤§è‡´æµç¨‹åˆ†ä¸ºäº†ä¸‰ä¸ªéƒ¨åˆ†ï¼š

1. **count**ï¼š ä¼°è®¡å™ªå£°æ ‡ç­¾å’ŒçœŸå®æ ‡ç­¾çš„è”åˆåˆ†å¸ƒ 
2. **clean**ï¼š  æ‰¾å‡ºå¹¶è¿‡æ»¤æ‰é”™è¯¯æ ·æœ¬  
3. **retrain**ï¼šè¿‡æ»¤é”™è¯¯æ ·æœ¬åï¼Œé‡æ–°è°ƒæ•´æ ·æœ¬ç±»åˆ«æƒé‡ï¼Œé‡æ–°è®­ç»ƒ 

ä¸‹é¢ç®€è¦ä»‹ç»ä¸‰ä¸ªæ­¥éª¤å…·ä½“çš„å®ç°ã€‚

#### 3.3.1counté˜¶æ®µ

é¦–å…ˆï¼Œcounté˜¶æ®µï¼Œæˆ‘ä»¬éœ€è¦ä¼°è®¡å™ªå£°æ ‡ç­¾å’ŒçœŸå®æ ‡ç­¾çš„è”åˆåˆ†å¸ƒã€‚å¸¸ç”¨çš„ä¼°è®¡è”åˆåˆ†å¸ƒçš„æ–¹æ³•å°±æ˜¯ä½¿ç”¨k-æŠ˜äº¤å‰éªŒè¯ï¼Œæˆ‘ä»¬åœ¨æœ¬æ¬¡å®éªŒä¸­ä¹Ÿæ˜¯ä½¿ç”¨çš„è¯¥æ–¹æ³•è¿›è¡Œä¼°è®¡ã€‚

è™½ç„¶è¯´cleanlabå·²ç»å°†å…¶å°è£…æˆä¸€ä¸ªç®€å•çš„å‡½æ•°æ¥å£ï¼Œä½†æ˜¯æˆ‘ä»¬ä½œä¸ºä½¿ç”¨è€…ï¼Œä¸ºäº†æé«˜åˆ†å¸ƒä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œä¹Ÿäº†è§£äº†å…¶ä¸­çš„åŸç†ã€‚æ‰€è°“k-æŠ˜äº¤å‰éªŒè¯ï¼Œå³å°†æ ·æœ¬åˆ†ä¸ºkä»½ï¼Œå…¶ä¸­1ä»½å½“ä½œæµ‹è¯•é›†ï¼Œå¦å¤–k-1ä»½å½“ä½œè®­ç»ƒé›†ï¼Œç”¨è¿›è¡Œè®­ç»ƒåçš„æ¨¡å‹å¯¹äºæµ‹è¯•é›†çš„æ ·æœ¬è¿›è¡Œé¢„æµ‹ï¼Œå¦‚æ­¤å³å¯å¾—åˆ°é‚£1ä»½æ ·æœ¬æ˜¯æœ‰æ•ˆè­¦å‘Šå’Œæ— æ•ˆè­¦å‘Šçš„æ¦‚ç‡ã€‚ä¸éš¾çœ‹å‡ºï¼Œåœ¨å™ªå£°æ•°é‡ä¸å˜ã€åˆ†å¸ƒå‡åŒ€çš„æƒ…å†µä¸‹ï¼Œkå–å€¼è¶Šå¤§ï¼Œé¢„æµ‹å‡ºçš„æ¦‚ç‡å°†è¶Šæ¥è¿‘çœŸå®å€¼ã€‚ä½†æ˜¯ä¸ºäº†é˜²æ­¢æ¦‚ç‡è¿‡äºæ¥è¿‘çœŸå®æ¦‚ç‡ï¼Œè€Œå‡ºç°æ¨¡å‹è¿‡æ‹Ÿåˆçš„æƒ…å†µï¼Œkå€¼ä¹Ÿä¸èƒ½è¿‡å¤§ã€‚

åœ¨æœ¬å®éªŒä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©k=10ä½œä¸ºäº¤å‰éªŒè¯çš„å‚æ•°ï¼Œä½¿ç”¨çš„æ˜¯sklearnåŒ…ä¸‹çš„äº¤å‰éªŒè¯çš„æ–¹æ³•ï¼Œè®­ç»ƒæ¨¡å‹é€‰æ‹©çš„æ˜¯kerasåŒ…ä¸‹çš„kerasClassifier()ï¼Œç”±äºå¯¹äºæ·±åº¦å­¦ä¹ é¢†åŸŸäº†è§£æœ‰é™ï¼Œæ‰€ä»¥å…¶ä¸­ç¥ç»ç½‘ç»œçš„æ„å»ºå€Ÿé‰´äºcleanlabå®˜æ–¹æ–‡æ¡£ã€‚å…¶ä¸­k-æŠ˜äº¤å‰éªŒè¯çš„è¿‡ç¨‹è¢«cross_val_predictæ–¹æ³•å°è£…ã€‚ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
import tensorflow as tf
from sklearn.model_selection import cross_val_predict
from scikeras.wrappers import KerasClassifier
def get_net():#æ„å»ºç¥ç»ç½‘ç»œ
    net = tf.keras.Sequential(
        [
            tf.keras.Input(shape=(None,), dtype="int64"),
            layers.Embedding(max_features + 1, 16),
            layers.Dropout(0.2),
            layers.GlobalAveragePooling1D(),
            layers.Dropout(0.2),
            layers.Dense(2),
            layers.Softmax()
        ]
    )  
    net.compile(
        optimizer="adam",
        loss=tf.keras.losses.SparseCategoricalCrossentropy(),
        metrics=tf.keras.metrics.CategoricalAccuracy(),
    )
    return net
model = KerasClassifier(get_net(), epochs=10)#æ„å»ºè®­ç»ƒæ¨¡å‹
k_folds = 10  # è®¾å®škå€¼
pred_probs = cross_val_predict(
    model,
    full_texts,
    full_labels,
    cv=k_folds,
    method="predict_proba",
)#k-æŠ˜äº¤å‰éªŒè¯
```

#### 3.3.2cleané˜¶æ®µ

å…¶æ¬¡ï¼Œcleané˜¶æ®µï¼Œæˆ‘ä»¬éœ€è¦æ‰¾å‡ºå¹¶è¿‡æ»¤æ‰é”™è¯¯æ ·æœ¬ã€‚é€šå¸¸æ¥è¯´æœ‰å‡ ç§å¸¸ç”¨çš„æ–¹æ³•æ¥é¢„æµ‹å™ªéŸ³ï¼š

1. ç›´æ¥é€‰å–é¢„æµ‹æ¦‚ç‡ä¸­æ¦‚ç‡è¾ƒå¤§çš„ä¸€ç±»ä¸äººå·¥æ ‡ç­¾è¿›è¡Œæ¯”å¯¹ï¼Œä¸ä¸€è‡´çš„æ ·æœ¬å°±æ˜¯å™ªéŸ³
2. æ„é€ è®¡æ•°çŸ©é˜µï¼Œç„¶åæŠŠéå¯¹è§’å•å…ƒçš„æ ·æœ¬ä½œä¸ºå™ªéŸ³ã€‚
3. Prune by classï¼Œå³å¯¹äºäººå·¥æ ‡è®°çš„æœ‰æ•ˆå’Œæ— æ•ˆï¼Œ ç­›é€‰æ¯ä¸ªç±»å±äºç»™å®šç±»æ ‡ç­¾çš„æ¦‚ç‡æœ€å°çš„æ ·æœ¬ ï¼ŒæŒ‰ç…§æœ€ä½æ¦‚ç‡è¿›è¡Œæ’åºã€‚
4. Prune by Noise Rateï¼Œå¯¹äºè®¡æ•°çŸ©é˜µçš„éå¯¹è§’å•å…ƒï¼Œï¼Œé€‰å–ä¸€å®šæ•°é‡æ ·æœ¬è¿›è¡Œè¿‡æ»¤ï¼Œå¹¶æŒ‰ç…§æ¦‚ç‡ç›¸å·®æœ€å¤§ï¼ˆæœ€å¤§é—´éš”ï¼‰è¿›è¡Œæ’åºã€‚

å…¶ä¸­å¦‚æœä½¿ç”¨ç¬¬ä¸€ç§æ–¹æ³•çš„è¯é‚£ä¹ˆå™ªéŸ³çš„æ•°é‡å°±ä¼šè¿‡äºå¤šè€Œå¯¼è‡´å™ªéŸ³ç”„åˆ«æ•ˆæœä¸ä½³ã€‚

è¿™é‡Œcleanlabä¹Ÿä¸ºæˆ‘ä»¬å°è£…å¥½äº†ä¸€ä¸ªæ¥å£ï¼Œå…¶ä¸­æˆ‘ä»¬å¯ä»¥é€šè¿‡filter_byå­—æ®µè¿›è¡Œcleanæ–¹æ³•çš„é€‰æ‹©ï¼Œä¸Šè¿°é™¤äº†ç¬¬1ç§æ–¹æ³•çš„ç¬¬2ï¼Œ3ï¼Œ4ç§æ–¹æ³•éƒ½å¯ä»¥é€‰æ‹©ã€‚é»˜è®¤ä½¿ç”¨PBCæ–¹æ³•ã€‚ç›´æ¥è°ƒç”¨å°±å¯ä»¥å¾—åˆ°ç»“æœã€‚æˆ‘ä»¬é€‰æ‹©çš„ä¹Ÿæ˜¯é»˜è®¤çš„PBCæ–¹æ³•ã€‚ä»£ç å¦‚ä¸‹å›¾æ‰€ç¤º

```python
from cleanlab.filter import find_label_issues

ranked_label_issues = find_label_issues(
    labels=full_labels, 
    pred_probs=pred_probs, 								           return_indices_ranked_by="self_confidence"
)#å¾—åˆ°ä¸€ä¸ªæœ€æœ‰å¯èƒ½æ˜¯å™ªå£°çš„æ ·æœ¬çš„ä¸‹æ ‡çš„listï¼ŒæŒ‰ç…§å¯èƒ½æ€§ä»é«˜åˆ°ä½è¿›è¡Œæ’åˆ—ã€‚
```

æ ¹æ®ç»“æœï¼Œæˆ‘ä»¬æ‰¾åˆ°äº†97ä¸ªå™ªéŸ³ï¼Œå…¶ä¸­æœ‰æ•ˆè­¦å‘Šä¸­çš„å™ªéŸ³æœ‰70ä¸ªï¼Œæ— æ•ˆè­¦å‘Šä¸­çš„å™ªéŸ³æœ‰27ä¸ªã€‚å½“ç„¶ï¼Œæ‰¾åˆ°çš„å™ªéŸ³æ•°é‡ä¹Ÿä¸æˆ‘ä»¬ä¹‹å‰è®¾å®šçš„å‚æ•°æœ‰å…³ã€‚æ¯”å¦‚è¯´ï¼Œåœ¨k-æŠ˜äº¤å‰éªŒè¯é˜¶æ®µè®¾å®škå€¼çš„æ—¶å€™ï¼Œå¦‚æœkå€¼è®¾å®šå¾—è¶Šå¤§ï¼Œé‚£ä¹ˆæ ‡ç­¾æ¦‚ç‡çš„åˆ†å¸ƒçš„é¢„æµ‹è¶Šæ¥è¿‘çœŸå®æƒ…å†µï¼Œé‚£ä¹ˆå¯¹äºå»å™ªæ¥è¯´ï¼Œå™ªå£°å°±ä¼šå› ä¸ºæ¦‚ç‡çš„æ¥è¿‘è€Œå˜å°‘ï¼Œä½†æ˜¯ï¼Œå¦‚æœkå€¼è®¾å®šå¾—è¶Šå°ï¼Œé‚£ä¹ˆæ ‡ç­¾æ¦‚ç‡åˆ†å¸ƒçš„é¢„æµ‹å°±ä¼šå˜å¾—æ¨¡ç³Šï¼Œåç¦»çœŸå®æƒ…å†µï¼Œé‚£ä¹ˆå™ªå£°å°±ä¼šå› ä¸ºæ¦‚ç‡çš„åå·®è€Œå˜å¤šã€‚

#### 3.3.3retrainé˜¶æ®µ

æœ€åï¼Œretrainé˜¶æ®µï¼Œè¿‡æ»¤é”™è¯¯æ ·æœ¬åï¼Œé‡æ–°è°ƒæ•´æ ·æœ¬ç±»åˆ«æƒé‡ï¼Œé‡æ–°è®­ç»ƒã€‚åœ¨cleanlabä¸­æä¾›çš„æ˜¯å°†åä¸¤ä¸ªé˜¶æ®µç”šè‡³ä¸‰ä¸ªé˜¶æ®µå°è£…åˆ°ä¸€èµ·çš„æ¥å£CleanLearning.fit() ã€‚å…¶ä¸­å¯ä»¥æä¾›è”åˆåˆ†å¸ƒæ¦‚ç‡ï¼Œä¹Ÿå¯ä»¥åªæä¾›è®­ç»ƒæ•°æ®å’Œè®­ç»ƒæ ‡ç­¾ã€‚å¦‚æœä¸æä¾›åˆ†å¸ƒæ¦‚ç‡çš„è¯fit()èƒ½å¤Ÿè‡ªåŠ¨è®¡ç®—å…¶æ¦‚ç‡ã€‚æˆ‘ä»¬çš„é€‰æ‹©æ˜¯è®©å…¶è‡ªåŠ¨è®¡ç®—å…¶åˆ†å¸ƒæ¦‚ç‡ã€‚ä»£ç å¦‚ä¸‹æ‰€ç¤º

```python
from cleanlab.classification import CleanLearning
model = KerasClassifier(get_net(), epochs=10)  # åˆå§‹åŒ–æ¨¡å‹
cl = CleanLearning(clf=model, seed=SEED)  # å°†æ¨¡å‹æ”¾å…¥cleanlabå°è£…å¥½çš„æ¨¡å‹ä¸­
_ = cl.fit(train_texts, train_labels) #åœ¨cleanlabä¸‹è¿›è¡Œè®­ç»ƒ
```

ç„¶åæˆ‘ä»¬éœ€è¦å°†ç”¨cleanlabè®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ä¸ä¸ä½¿ç”¨cleanlabè®­ç»ƒå‡ºçš„æ¨¡å‹è¿›è¡Œå¯¹ç…§å®éªŒï¼Œæ‰€ä»¥æˆ‘ä»¬è¿˜ä½¿ç”¨äº†å¸¸è§„çš„è®­ç»ƒæ–¹æ³•è®­ç»ƒäº†ä¸€ä¸ªæ¨¡å‹ã€‚ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
model = KerasClassifier(get_net(), epochs=10)# åˆå§‹åŒ–æ¨¡å‹
model.fit(train_texts, train_labels) #åœ¨å¸¸è§„æ¨¡å‹ä¸‹è¿›è¡Œè®­ç»ƒ
```

ç»è¿‡å¤šæ¬¡è®­ç»ƒæµ‹è¯•å®éªŒä¹‹åæˆ‘ä»¬å‘ç°ï¼Œå¯¹äºåœ¨cleanlabä¸Šçš„è®­ç»ƒçš„æ¨¡å‹åœ¨ç›¸å½“æ•°é‡çš„æƒ…å†µä¸‹æ‹Ÿåˆåº¦ä¼šç•¥ä¼˜äºå¸¸è§„æ¨¡å‹ï¼Œä½†æ˜¯åœ¨ä¸€éƒ¨åˆ†æƒ…å†µä¸‹cleanlabæ¨¡å‹çš„æ‹Ÿåˆåº¦ç”šè‡³ä¼šä½äºå¸¸è§„æ¨¡å‹ã€‚æˆ‘ä»¬æ¨æµ‹ä¸ºï¼Œè™½ç„¶è¯´è®­ç»ƒé›†ç»è¿‡äº†å»å™ªç¯èŠ‚ï¼Œä½†æ˜¯æµ‹è¯•é›†è¿˜æ²¡æœ‰ç»è¿‡å»å™ªï¼Œåœ¨è¿™æ ·çš„æƒ…å†µä¸‹ç”¨æµ‹è¯•é›†å»æµ‹è¯•æ¨¡å‹çš„æ‹Ÿåˆåº¦å®Œå…¨æœ‰å¯èƒ½ä¸‹é™ã€‚

### 3.4æ¨¡å‹æ ‡è®°ä¸äººå·¥æ ‡è®°æ¯”å¯¹

å³ä½¿ä¹‹å‰æˆ‘ä»¬å·²ç»ä½¿ç”¨äº†cleanlabå¯¹æ•°æ®é›†è¿›è¡Œäº†å»å™ªå’Œå†è®­ç»ƒä¹Ÿå¯¹æ¯”äº†cleanlabå’Œå¸¸è§„è®­ç»ƒæ¨¡å‹çš„æ‹Ÿåˆåº¦ã€‚ä½†æ˜¯è¿™äº›å§‹ç»ˆéƒ½æ˜¯åœ¨æœºå™¨è‡ªå·±è¯†åˆ«çš„è­¦å‘Šä¸­è¿›è¡Œäº’ç›¸çš„è®­ç»ƒã€è®¡ç®—ã€æ¯”å¯¹ã€å»å™ªç­‰ç­‰ã€‚è¦æƒ³éªŒè¯æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œè¿˜éœ€è¦å’Œäººå·¥æ ‡è®°çœŸå®è­¦å‘Šæ ‡è®°è¿›è¡Œæ¯”å¯¹ã€‚

æ­£å¦‚ä¸Šæ–‡æåˆ°çš„ï¼Œæˆ‘ä»¬åœ¨å»å™ªè¿‡ç¨‹ä¸­å‘ç°äº†97ä¸ªå™ªéŸ³ï¼Œå…¶ä¸­70ä¸ªä¸ºæœ‰æ•ˆè­¦å‘Šçš„å™ªéŸ³ï¼Œ27ä¸ªä¸ºæ— æ•ˆè­¦å‘Šçš„å™ªéŸ³ã€‚å¯¹äºçº¦4000æ¡è­¦å‘Šæ•°æ®è€Œè¨€ï¼Œè¿™ä¸ªæ•°æ®é‡æ— ç–‘æ˜¯è¾ƒå°‘çš„ï¼Œç›¸åº”çš„æ¨¡å‹çš„å¬å›ç‡å¯èƒ½å°±æ¯”è¾ƒä½ã€‚æˆ‘ä»¬äººå·¥æ ‡è®°å‡ºçš„å™ªéŸ³æœ‰655æ¡ï¼Œä½†æ˜¯é‰´äºæˆ‘ä»¬ä¸èƒ½ä¿è¯655æ¡ä¸­æ¯ä¸€æ¡éƒ½æ˜¯æ­£ç¡®çš„ï¼Œæˆ‘ä»¬è¿™ä¸ªæ¯”å¯¹ä¹Ÿåªèƒ½ä»…ä¾›å‚è€ƒã€‚ä½†æ˜¯é‰´äºæœ¬å®éªŒä¸»è¦å…³æ³¨çš„æ˜¯ç²¾åº¦ï¼Œä¹Ÿå°±æ˜¯åœ¨æˆ‘ä»¬æ‰¾åˆ°çš„97ä¸ªå™ªéŸ³ä¸­ï¼Œæœ‰å¤šå°‘å™ªéŸ³æ˜¯çœŸæ­£çš„å™ªéŸ³ï¼ˆTPï¼‰ã€‚ç»è¿‡æˆ‘ä»¬çš„ç»Ÿè®¡ï¼Œ97ä¸ªå™ªéŸ³ä¹‹ä¸­ï¼Œ54ä¸ªæ˜¯çœŸå™ªéŸ³ï¼ˆTPï¼‰ï¼Œå³ç²¾åº¦å¤§çº¦ä¸º55.67%ã€‚ç„¶åå…·ä½“çš„æ··æ·†çŸ©é˜µå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<img src="C:\Users\86139\Desktop\å±å¹•æˆªå›¾ 2022-12-01 183334.png" style="zoom:300%;" />

å¦å¤–ï¼Œæˆ‘ä»¬ä¹‹å‰è¿˜ä½¿ç”¨è¿‡å…¶ä»–çš„å‚æ•°ç»„åˆã€‚ç»è¿‡å¤šæ¬¡å®éªŒæˆ‘ä»¬å‘ç°ï¼Œå½“æ¨¡å‹çš„æ‹Ÿåˆæ•ˆæœè¶Šå¥½çš„æ—¶å€™ï¼Œå™ªå£°å°±è¶Šå°ï¼Œä½†æ˜¯å…¶ç²¾åº¦å°±ä¼šå¤§å¤§æå‡ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬æ›¾ç»åªå‘ç°äº†21ä¸ªå™ªå£°ï¼Œä½†æ˜¯å…¶ä¸­18ä¸ªéƒ½æ˜¯çœŸå™ªå£°ï¼ˆTP)ï¼Œç²¾åº¦è¾¾åˆ°äº†85.71%ã€‚å¯è§ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ç²¾åº¦å’Œå¬å›ç‡ä¹‹é—´åšä¸€ä¸ªæƒè¡¡ï¼Œæˆ‘ä»¬æ—¢è¦ä¿è¯æˆ‘ä»¬æ‰¾åˆ°çš„å™ªå£°ç²¾åº¦è¾¾åˆ°ä¸€å®šæ°´å¹³ï¼Œä¹Ÿè¦ä¿è¯æˆ‘ä»¬çš„å™ªå£°æ•°é‡æœ‰ä¸€å®šä¿è¯ã€‚

ä½†æ˜¯æˆ‘ä»¬è®¤ä¸ºå¯¹äºè®­ç»ƒå‚æ•°çš„è°ƒæ•´è€Œäº¤æ¢æ¥çš„æ”¶ç›Šåªæ˜¯æ²»æ ‡ä¸æ²»æœ¬çš„ï¼Œéœ€è¦ä»æ ¹æœ¬ä¸Šæé«˜æ¨¡å‹çš„æ‹Ÿåˆåº¦å’Œå™ªå£°çš„ç²¾åº¦ã€‚è‡³å°‘å…ˆä»è®­ç»ƒæ•°æ®é›†ä¸Šå…¥æ‰‹ï¼Œæœ‰å¾ˆå¤šæœ‰æ•ˆçš„ä¿¡æ¯åœ¨æ”¶é›†æ•°æ®é›†é¡¹ç›®ä¸­éƒ½æ²¡æœ‰æ”¶é›†åˆ°ï¼Œæˆ‘ä»¬å®Œå…¨å¯ä»¥æ”¶é›†å¯¹åº”ä½ç½®çš„æºç ç›¸å…³çš„ä¿¡æ¯ã€‚ä¾‹å¦‚å¯¹äºDEAD_LOCAL_STOREç±»å‹çš„è­¦å‘Šï¼Œæˆ‘ä»¬å°±åº”è¯¥ç»§ç»­æ‰«ææºç åé¢çš„éƒ¨åˆ†ï¼Œå°†å…¶åé¢æ˜¯å¦æœ‰ä½¿ç”¨è¿‡è¿™ä¸€å˜é‡ä½“ç°åœ¨è­¦å‘Šæ•°æ®é›†ä¸­ï¼Œè¿™æ ·æ¨¡å‹å¯ä»¥ç›´è§‚åœ°å­¦ä¹ åˆ°è¯¥è­¦å‘Šæ˜¯å¦æ˜¯ä¸€ä¸ªæœ‰æ•ˆè­¦å‘Šã€‚å†æ¯”å¦‚CATCH_EXCEPTIONç±»å‹çš„è­¦å‘Šï¼Œæˆ‘ä»¬å°±åº”è¯¥æ‰«æå‰é¢æ‰€ä½¿ç”¨çš„å˜é‡ç±»å‹éœ€è¦catchå“ªäº›ç±»å‹çš„exceptionï¼Œè¿™æ ·ç›´è§‚çš„ä¿¡æ¯å°†ä¼šæ¯”è­¦å‘Šåœ¨æºç ä¸­çš„ä½ç½®è¿™ç§æ¨¡ç³Šä¿¡æ¯æ›´å®¹æ˜“è®­ç»ƒã€‚

## 4.é¡¹ç›®è¯´æ˜

### 4.1è¿è¡Œç¯å¢ƒ

æ•°æ®é›†æ”¶é›†éƒ¨åˆ†ï¼š

//todo

ç½®ä¿¡å­¦ä¹ éƒ¨åˆ†:

Ubuntu 22.04

conda 22.9.0

python 3.9.13

tensorflow 2.7.0

cleanlab 2.1.0

### 4.2é¡¹ç›®æ„æˆ

æœ¬é¡¹ç›®å¤§æ¦‚åˆ†æˆä»¥ä¸‹å‡ å¤§æ¿å—

1. æ”¶é›†è­¦å‘Šæ•°æ®é›†çš„é¡¹ç›®findbugs-violation
2. æ”¶é›†è­¦å‘Šæ•°æ®é›†çš„ç›®æ ‡é¡¹ç›®biojava
3. åˆå§‹è­¦å‘Šæ•°æ®é›†txtæ–‡ä»¶(æœ‰æ•ˆè­¦å‘Š.txtã€æ— æ•ˆè­¦å‘Š.txtã€å…¨éƒ¨è­¦å‘Šç»Ÿè®¡.txtã€æœ‰æ•ˆè­¦å‘Šç»Ÿè®¡.txt)
4. æ ‡è®°åçš„è­¦å‘Šæ•°æ®é›†txtæ–‡ä»¶(è­¦å‘Šæ ‡è®°æ•´åˆ.txt)
5. è¿›è¡Œæ•°æ®é›†å¤„ç†çš„pythonæ–‡ä»¶(process-dataset.py)
6. é¢„å¤„ç†åçš„æ•°æ®é›†txtæ–‡ä»¶ï¼ˆæœ‰æ•ˆè­¦å‘Š(modified).txtã€æ— æ•ˆè­¦å‘Š(modified).txtï¼‰
7. è¿›è¡Œç½®ä¿¡å­¦ä¹ çš„pythonæ–‡ä»¶ï¼ˆconfident-learning.pyï¼‰

ä¸‹é¢æˆ‘åˆ†åˆ«ä»‹ç»å„æ–‡ä»¶çš„å†…å®¹å’Œä½œç”¨

#### 4.2.1 findbugs-violation

//todo

#### 4.2.2 biojava

æ”¶é›†è­¦å‘Šæ•°æ®é›†çš„ç›®æ ‡é¡¹ç›®ï¼Œå¯¹äºè¿™ä¸ªé¡¹ç›®çš„ä½¿ç”¨åªå­˜åœ¨äºå¯¹è­¦å‘Šè¿›è¡Œäººå·¥æ ‡è®°çš„é˜¶æ®µã€‚å…ˆå°†é¡¹ç›®cloneåˆ°æœ¬åœ°ï¼Œç„¶åæ ¹æ®æ¯ä¸€æ¡è­¦å‘Šçš„commit id ï¼Œåœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹å‘½ä»¤è¡Œé”®å…¥

```
git reset --hard [commit id]
```

å°†å¯¹åº”commit idç‰ˆæœ¬çš„é¡¹ç›®ä»£ç æ‹‰å–åˆ°æœ¬åœ°ï¼Œç„¶åæ ¹æ®è­¦å‘Šæ•°æ®é›†ä¸­çš„è·¯å¾„æ‰¾åˆ°å¯¹åº”æŠ¥è­¦å‘Šçš„ä½ç½®ï¼Œè¿›è¡Œäººå·¥è¯†åˆ«è­¦å‘Šæ˜¯å¦ä¸ºæœ‰æ•ˆè­¦å‘Šã€‚

#### 4.2.3åˆå§‹è­¦å‘Šæ•°æ®é›†txtæ–‡ä»¶

å…¶ä¸­åŒ…æ‹¬å››ä¸ªæ–‡ä»¶ï¼šæœ‰æ•ˆè­¦å‘Š.txtã€æ— æ•ˆè­¦å‘Š.txtã€å…¨éƒ¨è­¦å‘Šç»Ÿè®¡.txtã€æœ‰æ•ˆè­¦å‘Šç»Ÿè®¡.txtï¼Œä¸‹é¢åˆ†åˆ«ä»‹ç»å…¶ä¸­å†…å®¹ã€‚

**æœ‰æ•ˆè­¦å‘Š.txt**:è®°å½•äº†æ‰€æœ‰biojavaä¸­é€šè¿‡findbugsæ ‡è®°å‡ºçš„æœ‰æ•ˆè­¦å‘Šï¼Œå½¢å¦‚ä¸‹è¡¨ï¼ˆè¡¨é¡¹æ•°æ®ä¸ºç¤ºä¾‹ï¼‰



| è­¦å‘Šç±»å‹     | æŠ¥è­¦å‘Šç‰ˆæœ¬çš„commit id | è­¦å‘Šåœ¨é¡¹ç›®ä¸­çš„ä½ç½®     | è­¦å‘Šæ¶ˆå¤±ç‰ˆæœ¬çš„commit id | è­¦å‘Šæ¶ˆå¤±ç‰ˆæœ¬æ—¶åœ¨é¡¹ç›®ä¸­çš„ä½ç½® | æœ‰æ•ˆ |
| ------------ | --------------------- | ---------------------- | ----------------------- | ---------------------------- | ---- |
| æœªä½¿ç”¨çš„æ•°æ® | ....                  | ..../main/..../xx.java | ......                  | ..../main/..../xx.java       | æ˜¯   |

**æ— æ•ˆè­¦å‘Š.txt**:è®°å½•äº†æ‰€æœ‰biojavaä¸­é€šè¿‡findbugsæ ‡è®°å¤„çš„æ— æ•ˆè­¦å‘Šï¼Œå½¢å¦‚ä¸‹è¡¨ï¼ˆè¡¨é¡¹æ•°æ®ä¸ºç¤ºä¾‹ï¼‰



| è­¦å‘Šç±»å‹     | æŠ¥è­¦å‘Šç‰ˆæœ¬çš„commit id | åœ¨é¡¹ç›®ä¸­çš„ä½ç½®         | æœ‰æ•ˆ |
| ------------ | --------------------- | ---------------------- | ---- |
| æœªä½¿ç”¨çš„æ•°æ® | ....                  | ..../main/..../xx.java | å¦   |

**å…¨éƒ¨è­¦å‘Šç»Ÿè®¡.txtï¼š**è®°å½•äº†æ‰€æœ‰è­¦å‘Šä¸­è­¦å‘Šç±»å‹çš„å‡ºç°æ¬¡æ•°ï¼Œä»¥åŠè­¦å‘Šç±»å‹å¯¹åº”çš„å¤§ç±»ï¼Œå½¢å¦‚ä¸‹è¡¨ï¼ˆè¡¨é¡¹æ•°æ®ä¸ºç¤ºä¾‹ï¼‰

| Violation Type        | Occurrence | Category     |
| --------------------- | ---------- | ------------ |
| SE_NO_SERIALVERSIONID | 5195       | Bad practice |

**æœ‰æ•ˆè­¦å‘Šç»Ÿè®¡.txt**:è®°å½•äº†æ‰€æœ‰æœ‰æ•ˆè­¦å‘Šä¸­è­¦å‘Šç±»å‹çš„å‡ºç°æ¬¡æ•°ï¼Œä»¥åŠè­¦å‘Šç±»å‹å¯¹åº”çš„å¤§ç±»ï¼Œå½¢å¦‚ä¸‹è¡¨ï¼ˆè¡¨é¡¹æ•°æ®ä¸ºç¤ºä¾‹ï¼‰

| Violation Type                  | Occurrence | Category    |
| ------------------------------- | ---------- | ----------- |
| SIC_INNER_SHOULD_BE_STATIC_ANON | 10         | Performance |

#### 4.2.4æ ‡è®°åçš„è­¦å‘Šæ•°æ®é›†txtæ–‡ä»¶

åŒ…å«ä¸€ä¸ªæ–‡ä»¶ï¼š**è­¦å‘Šæ ‡è®°æ•´åˆ.txt**ï¼šå…¶ä¸­è®°å½•äº†2000æ¡æ­£å‘Šå’Œ2000æ¡è¯¯å‘Šçš„äººå·¥æ ‡è®°ï¼Œå…¶ä¸­æ ‡è®°ä¸­çš„â€œ1â€è¡¨ç¤ºcloseï¼Œâ€œ2â€è¡¨ç¤ºopenï¼Œâ€œ3â€è¡¨ç¤ºunknownï¼Œå½¢å¦‚ä¸‹è¡¨ï¼ˆè¡¨é¡¹æ•°æ®ä¸ºç¤ºä¾‹ï¼‰

æœ‰æ•ˆè­¦å‘Šæ ‡è®°æ ·æœ¬ï¼š

| è­¦å‘Šç±»å‹     | æŠ¥è­¦å‘Šç‰ˆæœ¬çš„commit id | è­¦å‘Šåœ¨é¡¹ç›®ä¸­çš„ä½ç½®     | è­¦å‘Šæ¶ˆå¤±ç‰ˆæœ¬çš„commit id | è­¦å‘Šæ¶ˆå¤±ç‰ˆæœ¬æ—¶åœ¨é¡¹ç›®ä¸­çš„ä½ç½® | æœ‰æ•ˆ | æ ‡è®° |
| ------------ | --------------------- | ---------------------- | ----------------------- | ---------------------------- | ---- | ---- |
| æœªä½¿ç”¨çš„æ•°æ® | ....                  | ..../main/..../xx.java | ......                  | ..../main/..../xx.java       | æ˜¯   | 1    |

æ— æ•ˆè­¦å‘Šæ ‡è®°æ ·æœ¬

| è­¦å‘Šç±»å‹     | æŠ¥è­¦å‘Šç‰ˆæœ¬çš„commit id | åœ¨é¡¹ç›®ä¸­çš„ä½ç½®         | æœ‰æ•ˆ | æ ‡è®° |
| ------------ | --------------------- | ---------------------- | ---- | ---- |
| æœªä½¿ç”¨çš„æ•°æ® | ....                  | ..../main/..../xx.java | å¦   | 2    |

#### 4.2.5è¿›è¡Œæ•°æ®é›†å¤„ç†çš„pythonæ–‡ä»¶

åŒ…å«ä¸€ä¸ªæ–‡ä»¶ï¼š**process-dataset.py**ï¼š

psï¼šå¯¹äºä»£ç ä¸­çš„è·¯å¾„éœ€è¦ä¿®æ”¹ä¸ºå¯¹åº”çš„è·¯å¾„ï¼Œå½“å‰å±•ç¤ºçš„æ˜¯ä»£ç åœ¨Ubuntuè™šæ‹Ÿæœºè¿è¡Œæ—¶çš„è·¯å¾„

å…¶ä¸­å¯¹äºæœ‰æ•ˆè­¦å‘Š.txtå’Œæ— æ•ˆè­¦å‘Š.txtåšäº†å¦‚ä¸‹å¤„ç†ï¼š

1. é¦–å…ˆæ ¹æ®pythonè‡ªå¸¦çš„gitåŒ…ï¼Œè·å–æ¯æ¡æ•°æ®å¯¹åº”commit idçš„æ—¶é—´å…ˆåé¡ºåºï¼Œç„¶åå°†commit idç”¨commitçš„æ—¥æœŸæ—¶é—´æ›¿æ¢ä¹‹ã€‚

   ```python
   from git.repo import Repo #python è‡ªå¸¦çš„gitåŒ…ï¼Œä¾¿äºæˆ‘ä»¬æ’°å†™è„šæœ¬
   import datetime
   
   git_repo_dir='/home/shenyujie/automaticTesting/biojava'
   
   def get_commit_time(commit_id):#æ ¹æ®commit idè·å–commitæ—¶é—´çš„æ–¹æ³•
       repo = Repo(git_repo_dir)
       commit = repo.commit(commit_id)
       return commit.committed_date
   
   #ä¸‹é¢åˆ†åˆ«å°†æœ‰æ•ˆè­¦å‘Š.txtå’Œæ— æ•ˆè­¦å‘Š.txtä¸­çš„commit id å…¨éƒ¨æ›¿æ¢ä¸º commitæ—¶é—´å¹¶åˆ†åˆ«å­˜æ”¾åœ¨æœ‰æ•ˆè­¦å‘Š(modified).txtå’Œæ— æ•ˆè­¦å‘Š(modified).txtä¸­
   f = open("/home/shenyujie/dataset/æœ‰æ•ˆè­¦å‘Š.txt")
   s = f.read() 
   s = s.replace(":"," ")
   s = s.replace("=>"," ")
   f.close()
   res = ""
   array = s.split("\n")
   for i in range(0,len(array)):
       subArray = array.split(" ")
       for j in range(0,len(subArray)):
           if j != 3:
               res = res + subArray + " "
           else:
               strDate = datetime.datetime.strftime(get_commit_time(subArray[j]),"%Y%m%d%H%M%S")
               res = res + strDate + " "
       res = res + "\n"    
   f = open("/home/shenyujie/dataset/æœ‰æ•ˆè­¦å‘Š(modified).txt","w")
   f.write(res)
   f.close()
   
   f = open("/home/shenyujie/dataset/æ— æ•ˆè­¦å‘Š.txt")
   s = f.read() 
   s = s.replace(":"," ")
   s = s.replace("ï¼Œ"," ")
   f.close()
   res = ""
   array = s.split("\n")
   for i in range(0,len(array)):
       subArray = array.split(" ")
       for j in range(0,len(subArray)):
           if j != 3:
               res = res + subArray + " "
           else:
               strDate = datetime.datetime.strftime(get_commit_time(subArray[j]),"%Y%m%d%H%M%S")
               res = res + strDate + " "
       res = res + "\n"    
   f = open("/home/shenyujie/dataset/æ— æ•ˆè­¦å‘Š(modified).txt","w")
   f.write(res)
   f.close()
   
   ```

   

2. ç„¶åæ ¹æ®è­¦å‘Šç±»å‹å±äºæŸä¸€ä¸ªè­¦å‘Šå¤§ç±»ï¼Œå°†å…¶è­¦å‘Šå¤§ç±»çš„ä¿¡æ¯æ·»åŠ åˆ°å¯¹åº”çš„æ ·æœ¬ä¸­

   psï¼šå¯¹äºä»£ç ä¸­çš„è·¯å¾„éœ€è¦ä¿®æ”¹ä¸ºå¯¹åº”çš„è·¯å¾„ï¼Œå½“å‰å±•ç¤ºçš„æ˜¯ä»£ç åœ¨Ubuntuè™šæ‹Ÿæœºè¿è¡Œæ—¶çš„è·¯å¾„

   ```python
   #å»ºç«‹ä¸€ä¸ªè­¦å‘Šç±»å‹åˆ°å¤§ç±»çš„æ˜ å°„è¡¨
   f = open("/home/shenyujie/dataset/å…¨éƒ¨è­¦å‘Šç»Ÿè®¡.txt")
   s = f.read()
   s = s.replace(";"," ")
   f.close()
   typeMap = split("\n") 
   for i in range(0,len(typeMap)):
       typeMap[i] = typeMap[i].split(" ")
   
   #ç»™æœ‰æ•ˆè­¦å‘Š(modified).txtçš„æ•°æ®é›†æ·»åŠ ä¸Šè­¦å‘Šç±»å‹å¤§ç±»
   f = open("/home/shenyujie/dataset/æœ‰æ•ˆè­¦å‘Š(modified).txt")
   s = f.read()
   f.close()
   res = ""
   array = s.split("\n")
   for i in range(0,len(array)):
       subArray = array[i].split(" ")
       bigType = ""
       for j in range(0,len(typeMap)):
           if subArray[0] == typeMap[j][1]:
               res = res + typeMap[j][3] + " "+ array[i] + "\n"
               break
   f = open("/home/shenyujie/dataset/æœ‰æ•ˆè­¦å‘Š(modified).txt","w")
   f.write(res)
   f.close()
   
   #ç»™æ— æ•ˆè­¦å‘Š(modified).txtçš„æ•°æ®é›†æ·»åŠ ä¸Šè­¦å‘Šç±»å‹å¤§ç±»
   f = open("/home/shenyujie/dataset/æ— æ•ˆè­¦å‘Š(modified).txt")
   s = f.read()
   f.close()
   res = ""
   array = s.split("\n")
   for i in range(0,len(array)):
       subArray = array[i].split(" ")
       bigType = ""
       for j in range(0,len(typeMap)):
           if subArray[0] == typeMap[j][1]:
               res = res + typeMap[j][3] + " "+ array[i] + "\n"
               break
   f = open("/home/shenyujie/dataset/æ— æ•ˆè­¦å‘Š(modified).txt","w")
   f.write(res)
   f.close()
   ```

   

#### 4.2.6 é¢„å¤„ç†åçš„æ•°æ®é›†txtæ–‡ä»¶

åŒ…å«ä¸¤ä¸ªæ–‡ä»¶ï¼šæœ‰æ•ˆè­¦å‘Š(modified).txtã€æ— æ•ˆè­¦å‘Š(modified).txt

**æœ‰æ•ˆè­¦å‘Š(modified).txt**ï¼š

ç»è¿‡process-dataset.pyæ–‡ä»¶å¤„ç†ä¹‹åï¼Œå…¶ä¸­çš„commit idä¸€åˆ—æ›´æ¢ä¸ºäº†commit timeï¼Œæ–°å¢äº†ä¸€åˆ—è¡¨ç¤ºè­¦å‘Šç±»å‹å¤§ç±»ã€‚å½¢å¦‚ä¸‹è¡¨ï¼ˆæ•°æ®é¡¹ä¸ºç¤ºä¾‹ï¼‰ï¼š



| è­¦å‘Šç±»å‹     | æŠ¥è­¦å‘Šç‰ˆæœ¬çš„commitæ—¶é—´ | è­¦å‘Šåœ¨é¡¹ç›®ä¸­çš„ä½ç½®     | è­¦å‘Šæ¶ˆå¤±ç‰ˆæœ¬çš„commit id | è­¦å‘Šæ¶ˆå¤±ç‰ˆæœ¬æ—¶åœ¨é¡¹ç›®ä¸­çš„ä½ç½® | è­¦å‘Šå¤§ç±»      |
| ------------ | ---------------------- | ---------------------- | ----------------------- | ---------------------------- | ------------- |
| æœªä½¿ç”¨çš„æ•°æ® | 20151022180536         | ..../main/..../xx.java | 201510232304            | ..../main/..../xx.java       | Bad  Practice |



**æ— æ•ˆè­¦å‘Š(modified).txtï¼š**

ç»è¿‡process-dataset.pyæ–‡ä»¶å¤„ç†ä¹‹åï¼Œå…¶ä¸­çš„commit idä¸€åˆ—æ›´æ¢ä¸ºäº†commit timeï¼Œæ–°å¢äº†ä¸€åˆ—è¡¨ç¤ºè­¦å‘Šç±»å‹å¤§ç±»ã€‚å½¢å¦‚ä¸‹è¡¨ï¼ˆæ•°æ®é¡¹ä¸ºç¤ºä¾‹ï¼‰ï¼š

| è­¦å‘Šç±»å‹     | æŠ¥è­¦å‘Šç‰ˆæœ¬çš„commit id | åœ¨é¡¹ç›®ä¸­çš„ä½ç½®         | è­¦å‘Šå¤§ç±»      |
| ------------ | --------------------- | ---------------------- | ------------- |
| æœªä½¿ç”¨çš„æ•°æ® | ....                  | ..../main/..../xx.java | Bad  Practice |

#### 4.2.7 è¿›è¡Œç½®ä¿¡å­¦ä¹ çš„pythonæ–‡ä»¶

åŒ…å«ä¸€ä¸ªæ–‡ä»¶ï¼šconfident-learning.py

æœ¬pythonæ–‡ä»¶ä¸ºç½®ä¿¡å­¦ä¹ çš„ä¸»è¦æ–‡ä»¶ã€‚ä¸»è¦å®Œæˆäº†ä»¥ä¸‹å·¥ä½œã€‚

1. æ•°æ®é›†å‡†å¤‡

2. ä½¿ç”¨cleanlabè¿›è¡Œå»å™ªã€‚

3. å°†cleanlabæ¨¡å‹è®­ç»ƒæ•ˆæœä¸å¸¸è§„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¯”å¯¹ã€‚

å…·ä½“ç»†èŠ‚è§ä»£ç æ³¨é‡Šã€‚

psï¼šå¯¹äºä»£ç ä¸­çš„è·¯å¾„éœ€è¦ä¿®æ”¹ä¸ºå¯¹åº”çš„è·¯å¾„ï¼Œå½“å‰å±•ç¤ºçš„æ˜¯ä»£ç åœ¨Ubuntuè™šæ‹Ÿæœºè¿è¡Œæ—¶çš„è·¯å¾„

   

```python
import re
import string
import pandas as pd
from sklearn.metrics import accuracy_score, log_loss
from sklearn.model_selection import cross_val_predict
import tensorflow as tf
from tensorflow.keras import layers
import tensorflow_datasets as tfds
from scikeras.wrappers import KerasClassifier

SEED = 123456  

#åŠ è½½æ•°æ®é›†
f = open("/home/shenyujie/dataset/æœ‰æ•ˆè­¦å‘Šä¿®æ”¹(modified).txt")
s = f.read()
f.close()
raw_full_texts = s.split("\n")
for i in range(0,len(raw_full_texts)-1):
    temp = raw_full_texts[i].split(" ")
    raw_full_texts[i] = ""    
    for j in range(0,7):
        raw_full_texts[i] = raw_full_texts[i] + temp[j] +" "


f = open("/home/shenyujie/dataset/æ— æ•ˆè­¦å‘Šä¿®æ”¹(modified).txt")
s = f.read()
f.close()
temp = s.split("\n")
for i in range(0,len(temp)):
    raw_full_texts.append(temp[i])

full_labels = []
for i in range(0,1967):
    full_labels.append(1)
for i in range(0,2186):
    full_labels.append(0)
    

# æ‰“ä¹±æ•°æ®é›†
import numpy as np
 
np.random.seed(123456)
np.random.shuffle(raw_full_texts)
np.random.seed(123456)
np.random.shuffle(full_labels)
np.random.seed(123456)

# è®¾å®šå°†æ–‡æœ¬å‚æ•°åŒ–çš„å‚æ•°ï¼Œå¹¶å°†è¾“å…¥æ–‡æœ¬å‚æ•°åŒ–
max_features = 10000
sequence_length = 100

vectorize_layer = layers.TextVectorization(
    
    max_tokens=max_features,
    output_mode="int",
    output_sequence_length=sequence_length,
)

vectorize_layer.adapt(raw_full_texts)
full_texts = vectorize_layer(raw_full_texts)
full_texts = full_texts.numpy()

# æ„å»ºç¥ç»ç½‘ç»œ
def get_net():
    net = tf.keras.Sequential(
        [
            tf.keras.Input(shape=(None,), dtype="int64"),
            layers.Embedding(max_features + 1, 16),
            layers.Dropout(0.2),
            layers.GlobalAveragePooling1D(),
            layers.Dropout(0.2),
            layers.Dense(num_classes),
            layers.Softmax()
        ]
    )  

    net.compile(
        optimizer="adam",
        loss=tf.keras.losses.SparseCategoricalCrossentropy(),
        metrics=tf.keras.metrics.CategoricalAccuracy(),
    )
    return net

# åˆå§‹åŒ–æ¨¡å‹
num_classes = len(set(full_labels))
model = KerasClassifier(get_net(), epochs=10)

# è®¾å®škå€¼å¹¶è¿›è¡ŒkæŠ˜äº¤å‰éªŒè¯
k_folds = 10 
pred_probs = cross_val_predict(
    model,
    full_texts,
    full_labels,
    cv=k_folds,
    method="predict_proba",
)


loss = log_loss(full_labels, pred_probs)  #å¯¹äºk-æŠ˜äº¤å‰éªŒè¯åŸºäºlosså€¼è¿›è¡Œè¯„ä¼°
print(f"Cross-validated estimate of log loss: {loss:.3f}")

# ä½¿ç”¨cleanlabå¯»æ‰¾å™ªå£°
from cleanlab.filter import find_label_issues

ranked_label_issues = find_label_issues(
    labels=full_labels, pred_probs=pred_probs, return_indices_ranked_by="self_confidence"
)
print(ranked_label_issues)

#--------------------------------------------------------------
# ä¸‹é¢å°†cleanlabä¸å¸¸è§„æ¨¡å‹çš„æ‹Ÿåˆç¨‹åº¦è¿›è¡Œæ¯”å¯¹
#--------------------------------------------------------------

# åŠ è½½æ•°æ®é›†
f = open("/home/shenyujie/dataset/æœ‰æ•ˆè­¦å‘Šä¿®æ”¹(modified).txt")
s = f.read()
f.close()
raw_full_texts = s.split("\n")

f = open("/home/shenyujie/dataset/æ— æ•ˆè­¦å‘Šä¿®æ”¹(modified).txt")
s = f.read()
f.close()
temp = s.split("\n")
print(len(temp))
for i in range(0,len(temp)):
    raw_full_texts.append(temp[i])
print(len(raw_full_texts))

full_labels = []
for i in range(0,1967):
    full_labels.append(1)
for i in range(0,2186):
    full_labels.append(0)
    
# æ‰“ä¹±æ•°æ®é›†
import numpy as np
 
np.random.seed(123456)
np.random.shuffle(raw_full_texts)
np.random.seed(123456)
np.random.shuffle(full_labels)
np.random.seed(123456)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
raw_train_texts = raw_full_texts[0:3200]
train_labels = full_labels[0:3200]
raw_test_texts = raw_full_texts[3200:len(raw_full_texts)]
test_labels = full_labels[3200:len(full_labels)]

# å‘é‡åŒ–æ•°æ®
vectorize_layer.reset_state()
vectorize_layer.adapt(raw_train_texts)

train_texts = vectorize_layer(raw_train_texts)
test_texts = vectorize_layer(raw_test_texts)

train_texts = train_texts.numpy()
test_texts = test_texts.numpy()

# å¸¸è§„æ¨¡å‹è¿›è¡Œè®­ç»ƒå¹¶æµ‹è¯•æ‹Ÿåˆåº¦
model = KerasClassifier(get_net(), epochs=10)
model.fit(train_texts, train_labels)

preds = model.predict(test_texts)
acc_og = accuracy_score(test_labels, preds)
print(f"\n Test accuracy of original neural net: {acc_og}")


# ä½¿ç”¨cleanlabè¿›è¡Œè®­ç»ƒå¹¶æµ‹è¯•æ‹Ÿåˆåº¦
from cleanlab.classification import CleanLearning

model = KerasClassifier(get_net(), epochs=10)  # Note we first re-instantiate the model
cl = CleanLearning(clf=model, seed=SEED)  # cl has same methods/attributes as model

_ = cl.fit(train_texts, train_labels)

pred_labels = cl.predict(test_texts)
acc_cl = accuracy_score(test_labels, pred_labels)
print(f"Test accuracy of cleanlab's neural net: {acc_cl}")
```

















