# 2022-自动化测试-警告识别

## 1.简介

本项目主要是基于置信学习技术，对apache项目中的警告数据集进行去噪。

本项目的工作主要分为两个阶段：第一个阶段，利用github上现有的项目

findbugs-violation (https://github.com/lxyeah/findbugs-violations) ，收集github上的apache项目的警告数据集。第二个阶段，利用cleanlab这一python包，对数据集进行去噪，并对模型进行训练。

下面我们将对于以下两个部分分别展开介绍我们的工作过程和心路历程。

## 2.数据集收集

## 3.基于置信学习去噪

### 3.1置信学习初探

首先，我们初步了解了置信学习领域，发现这是一个较为前沿的领域，可以借鉴的内容并不多。于是我们自己研读了有关置信学习的论文：Confident Learning: Estimating Uncertainty in Dataset Labels。对于置信学习有了一个初步的了解：大致就是先计算出数据标签的概率分布，然后跟人工标记的标签进行比对（此处则是findbugs自动标注的标签），最后找出最有可能是噪声的样本。对于大体的框架其实不难理解，但是落实到具体的算法之上就有些许黔驴技穷的感觉了。

### 3.2数据集预处理

对于第一阶段收集到的数据集而言，大致形如下表

有效警告：

| 警告类型     | 报警告版本的commit id | 警告在项目中的位置     | 警告消失版本的commit id | 警告消失版本时在项目中的位置 |
| ------------ | --------------------- | ---------------------- | ----------------------- | ---------------------------- |
| 未使用的数据 | ....                  | ..../main/..../xx.java | ......                  | ..../main/..../xx.java       |

无效警告：

| 警告类型     | 报警告版本的commit id | 在项目中的位置         |
| ------------ | --------------------- | ---------------------- |
| 未使用的数据 | ....                  | ..../main/..../xx.java |



得到数据集之后要考虑的就是选择一个合适的训练模型来输入数据集进行训练。

**训练模型的选择：**

我们也有考虑过基于表格数据和基于文本的形式来训练模型，但是受限于“警告在项目中的位置”之类的数据范围太大（即可能出现各种各样的路径），而且字符串长度过长，不利于当作表格数据进行训练。而对于基于文本训练的模型来说，数据范围略大并不会对于模型训练产生影响。比如对于表格数据来说，表项中的数据无非就是数字（int，float，double等），或者是一些类型（category）（eg：cash，credit card，wechat-pay，ali-pay等），数据范围略小。而文本数据来说，数据项类似于一段话这样的长字符串，而且没有任何限制，这样的数据范围较为适合训练警告数据集。

相比较而言，二者的共同点是：它们都将数据进行拆分然后转化成向量放入模型进行训练。不同点是：感觉上表格数据的取值是“离散”的，而文本数据的取值是“连续”的。

**数据特征的增加和优化**

对于第一阶段产生的数据而言，要想直接训练出一个拟合效果不错的模型无疑是困难的，所以说在这里我们小组也跟其他小组就数据集处理这个一问题进行了一些讨论。

对于这样的数据集来说，主要有两个问题：第一：特征维度来说过于低。第二：有效的训练特征更是不足。下面将分别展开对于这两个问题我们提供的改进方法。

/*

在阐述第一第二点之前，先阐述一下在模型训练过程中犯下的一个严重而又低级的错误

第零点：统一数据格式

因为正告数据集，跟误告数据集格式不同，所以如果直接把二者打乱进行训练的话模型很可能就仅仅根据格式上的不同而产生输出，这也是为什么在没有统一格式之前的拟合结果接近于100%的原因。

*/

第一：增加特征的维度

在警告数据集中的每一个警告都是来自于findbugs工具自带的警告类型。幸运的是，findbugs的文档中对于每个警告类型都归结为了一个大类型（也可以称之为警告级别（rank）），分别是  Bad practice ， Correctness ， Experimental ， Internationalization ， Malicious code vulnerability ， Malicious code vulnerability ， Performance ， Security ， Dodgy code 。其中每个类型也有对应的严重程度，例如 Bad practice就是一些编码的坏习惯，对于程序的正确正常运行没有太大影响，Correctness 就是会影响程序的正确运行的类型。所以说我们根据每个警告类型对应的警告级别，作为一个全新的维度也加入到了数据集当中。这将会更有利于模型学习到警告类型的特征。



第二：增加特征的有效性

对于commit id来说，本质上就是随机产生的一串字符，没有任何可以提取出来的特征。不难预料对于这样的数据类型放入模型训练之后学习的效果只会少之又少。通过小组间的讨论之后我们一致认为，commit id需要转换为一个可能会有产出的数据——commit 的日期，如果有了一个commit先后顺序的信息加入其中，可能会对模型的训练有所帮助。例如，2015年之前的警告大多都是无效警告。所以我们利用python自带的git包来把数据中所有的commit id更换成了commit的日期。



### 3.3置信学习去噪

### 3.4模型标记与人工标记比对

